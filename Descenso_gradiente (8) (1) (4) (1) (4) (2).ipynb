{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from random import seed\n",
    "from random import randrange\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lectura de datos\n",
    "data = sns.load_dataset('iris')\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiar ajuste de datos para clasificar setosa\n",
    "data['categoria'] = [1 if x =='setosa' else -1 for x in data['species']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función clasifica\n",
    "def clasifica(x, y, theta, theta_0):\n",
    "    \n",
    "    \"\"\" Def: evalua la prediccion\n",
    "    Inputs:\n",
    "    theta: vector\n",
    "    theta_0: escalar\n",
    "    x: vector de caracteristicas\n",
    "    y: vector de etiquetas\n",
    "\n",
    "    Outputs:\n",
    "    value: -1 si la clasific es incorrecta, 0 si lo es\n",
    "    \"\"\"\n",
    "    \n",
    "    if y*(np.dot(theta,np.transpose(y)) + theta_0) < 1 :\n",
    "        value = -1\n",
    "    else:\n",
    "        value = 0\n",
    "\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loess(x, y, theta, theta_0):\n",
    "    \"\"\" Evaluacion en la funcion de perdida\n",
    "    \n",
    "    Inputs:\n",
    "    x - vector de características\n",
    "    y - vector de etiquetas\n",
    "    theta - vector\n",
    "    theta_0 - escalar\n",
    "\n",
    "    Outputs:\n",
    "    suma = funcion perdida evaluada\n",
    "    \"\"\"\n",
    "    \n",
    "    suma = 0\n",
    "    H = 0\n",
    "    n = x.shape[0]\n",
    "    \n",
    "    for i in range(n):\n",
    "        H = y[i]*(np.dot(theta, x[i]) + theta_0)\n",
    "        if H >= 1:\n",
    "            suma += 0\n",
    "        else:\n",
    "            suma += (1-H)\n",
    "            \n",
    "    return suma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jacob(X, Y, theta, theta_0, lamb):\n",
    "    \"\"\" Calculo del jacobiano\n",
    "    \n",
    "    X - matriz de características\n",
    "    Y - vector de etiquetas\n",
    "    theta - vector\n",
    "    theta0 - escalar\n",
    "    lamb - escalar\n",
    "\n",
    "    Outputs:\n",
    "    value = valor del jacobiano\n",
    "     \"\"\"\n",
    "    \n",
    "    n = X.shape[0]\n",
    "    jac = loess(X, Y, theta, theta_0)/n + (lamb/2.0)*np.linalg.norm(theta)\n",
    "\n",
    "    return jac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para descenso por gradiente\n",
    "def SVM(X, Y, theta, theta_0, etha, lamb, eps = 1e-8, MAX = 3000):\n",
    "    \"\"\" Support Vector Machine (SVM) utilizando el metodo de descenso en gradiente\n",
    "    \n",
    "    Inputs:\n",
    "    X - matriz de características\n",
    "    Y - vector de etiquetas\n",
    "    theta - vector inicial\n",
    "    theta_0 - escalar\n",
    "    etha - escalar\n",
    "    lamb - escalar\n",
    "    \n",
    "    Outputs:\n",
    "    theta = hiperplano final\n",
    "    theta_0 = base del hiperplano final\n",
    "    \"\"\"\n",
    "    \n",
    "    n = X.shape[0]\n",
    "    print('n de X: ', n)\n",
    "    sum_theta = 0\n",
    "    sum_theta_0 = 0\n",
    "    error = 10\n",
    "    t = 0\n",
    "    \n",
    "    while error >= eps and t < MAX:\n",
    "        # Guardar parametros en tiempo: t-1\n",
    "        theta_old = theta\n",
    "        theta_0_old = theta_0\n",
    "        \n",
    "        # Evaluacion de la suma para la actualizacion el descenso por gradiente\n",
    "        for i in range(n):\n",
    "            sum_theta += clasifica(X[i], Y[i], theta, theta_0)*Y[i]*X[i]\n",
    "            sum_theta_0 += clasifica(X[i], Y[i], theta, theta_0)*Y[i]\n",
    "        \n",
    "        # Descenso por gradiente\n",
    "        print('n para descenso: ', n)\n",
    "        theta = theta - etha*((sum_theta/n) + lamb*theta)\n",
    "        theta_0= theta_0 - etha*((sum_theta_0/n))\n",
    "        \n",
    "        # Calculo del error\n",
    "        error = abs(jacob(X, Y, theta, theta_0, lamb) - jacob(X, Y, theta_old, theta_0_old, lamb))\n",
    "        t += 1\n",
    "    \n",
    "    jac = jacob(X, Y, theta, theta_0, lamb)\n",
    "    return theta, theta_0, t, error, jac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CV_SVM(D, k, theta, theta_0, etha, lamb):\n",
    "    \"\"\" Funcion que realiza la validación cruzada para determinar con que hiperprámetros se minimiza el error\n",
    "    \n",
    "    Inputs:\n",
    "    df - Data frame del conjunto de entrenamiento\n",
    "    k - El número de subcojunto de datos en el cual se desea dividir el set de train\n",
    "    theta_ - Hiperparametro de iniciacion para la funcion de SVM\n",
    "    theta0: - Hiperparametro de iniciacion para la funcion de SVM\n",
    "    eta - Hiperparametro para la funcion de SVM\n",
    "    lambda_ - Hiperparametro para la funcion de SVM\n",
    "\n",
    "    Outputs:\n",
    "    resultados - Error promedio de clasificacion\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    errors = []\n",
    "    n = D.shape[0]  # Para saber el número de renglones totales\n",
    "    n = int((n / k))  # Si k = 5 los chunks tienen 24 observaciones  \n",
    "    \n",
    "    for i in range (k):\n",
    "        \n",
    "        init = n*i\n",
    "        fin = n*(n + i)\n",
    "        test_i = D.iloc[init:fin, :]\n",
    "        train_i = D.drop(test_i.index)\n",
    "        \n",
    "        X_train = train_i.iloc[:,0:4]\n",
    "        X_train = X_train.to_numpy()\n",
    "        Y_train = train_i.iloc[:,5]\n",
    "        Y_train = Y_train.to_numpy()\n",
    "        theta,theta_0 = SVM(X = X_train, Y = Y_train, theta = theta , theta_0 = theta_0, etha = etha, lamb = lamb)\n",
    "        \n",
    "        #Se calcula el error en esa primer corrida\n",
    "        \n",
    "        X_test = test_i.iloc[:,0:4]\n",
    "        X_test = X.to_numpy()\n",
    "        Y_test = test_i.iloc[:,5]\n",
    "        Y_test = Y.to_numpy()\n",
    "        error_i = error(X = X_test, Y = Y_test, theta = theta, theta_0 = theta_0)\n",
    "        errors.append(error_i)\n",
    "    \n",
    "    error_promedio = np.mean(errors)\n",
    "\n",
    "    return error_promedio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(X, Y, theta, theta_0):\n",
    "    \"\"\" Evaluacion del error\n",
    "    \n",
    "    Inputs:\n",
    "    X - vector de caracteristicas numericas\n",
    "    Y - vector de etiquetas de las características (-1 o 1)\n",
    "    theta = vector\n",
    "    theta_0 = escalar\n",
    "    \n",
    "    Outputs:\n",
    "    error_prom - error promedio de las observaciones que son mal clasificadas\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    n = len(X)\n",
    "    suma = 0\n",
    "    error_prom = 0\n",
    "    \n",
    "    X = np.squeeze(np.asarray(X))\n",
    "    Y = np.squeeze(np.asarray(Y))\n",
    "    \n",
    "    for i in np.arange(n):\n",
    "        clasificador = Y[i]*((np.dot(theta,X[i])) + theta_0)\n",
    "        if clasificador <= 0:\n",
    "            suma += 1         \n",
    "    error_prom += suma\n",
    "    \n",
    "    error_prom = error_prom/n\n",
    "    \n",
    "    return error_prom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD(X, Y, lamb, eps = 1e-8, T = 5000):\n",
    "    \"\"\" Funcion que los parámetros del modelo perceptron \n",
    "    Inputs:\n",
    "    X_array - arreglo de caracteristicas numericas\n",
    "    y_array - arreglo etiquetas de las características (-1 o 1)\n",
    "    Nota: se asume que X y y tienen la misma cantidad de registros\n",
    "    \n",
    "    T -  Número de iteraciones\n",
    "    lambda_ - Párametro lambda \n",
    "    \n",
    "    Outputs:\n",
    "    theta_t - parámetro theta e intercepto (theta_t[-1])\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    n = X.shape[0]\n",
    "    X = np.matrix(X)\n",
    "    ones = np.matrix(np.ones((X.shape[0],1)))\n",
    "    X = np.append(X, ones, axis=1)\n",
    "    Y = np.matrix(Y).reshape(Y.shape[0],1)\n",
    "    theta_t = np.matrix(np.zeros(X.shape[1]))\n",
    "    \n",
    "    for t in range(T):\n",
    "        i = np.random.randint(n)\n",
    "        etha = 1/(t+1)\n",
    "        theta_t = np.squeeze(np.asarray(theta_t))\n",
    "        x_i = np.squeeze(np.asarray(X[i]))\n",
    "        \n",
    "        if np.dot(theta_t,x_i)*Y[i] < 1:\n",
    "            l_h =  -1\n",
    "        else:\n",
    "            l_h =  0\n",
    "        \n",
    "        theta_t = theta_t - etha*(l_h*Y[i]*x_i + (lamb)*theta_t)\n",
    "        \n",
    "    return np.array(theta_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CV_SGD(D, k, lamb):\n",
    "    \"\"\" Funcion que realiza la validación cruzada para determinar con que hiperprámetros se minimiza el error\n",
    "    Inputs:\n",
    "    df - Data frame del conjunto de entrenamiento\n",
    "    k - El número de subcojunto de datos en el cual se desea dividir el set de train\n",
    "\n",
    "    Outputs:\n",
    "    resultados - Un data frame que arroja los errores para cada k \n",
    "    \"\"\"\n",
    "    \n",
    "    errors = []\n",
    "    n = D.shape[0]\n",
    "    n = int((n / k))\n",
    "    \n",
    "    for i in range (0,k):\n",
    "        init = n*i\n",
    "        fin = n*(1+i)\n",
    "        test_i = D.iloc[init:fin,:]\n",
    "        train_i = D.drop(test_i.index)\n",
    "        \n",
    "        # Calcular theta y theta_0 con SGD y train\n",
    "        X = train_i.iloc[:,0:4]\n",
    "        Y = train_i.iloc[:,5]\n",
    "        theta_t = SGD(X = X, Y = Y, lamb = lamb)\n",
    "        theta = theta_t[0,0:-1]\n",
    "        theta_0 = theta_t[0,-1]\n",
    "        \n",
    "        #Se calcula el error en esa primer corrida\n",
    "        X = test_i.iloc[:,0:4]   #Columna con las 4 características\n",
    "        Y = test_i.iloc[:,5]    #Columna con el vector de etiquetas\n",
    "        e_i = error(X = X, Y = Y, theta = theta, theta_0 = theta_0)\n",
    "        errors.append(e_i)\n",
    "    \n",
    "    error_promedio = np.mean(errors)\n",
    "\n",
    "    return error_promedio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar datos para prueba y entrenamiento\n",
    "np.random.seed(2020)\n",
    "train = data.sample(frac = 0.8, random_state = 2020) # Fijamos la semilla con random_state\n",
    "test = data.drop(train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# Probar SGD\n",
    "error_sgd = []\n",
    "lambdas = [1e-4, 1e-3, 1e-2,  1e-1,  1]\n",
    "for lamb in lambdas:\n",
    "    error_sgd.append(CV_SGD(D = train, k = 5, lamb = lamb))\n",
    "\n",
    "print(error_sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe58128d6a0>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot((lambdas), (error_sgd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.07138148  1.53862499 -1.81551524 -0.64653109]\n",
      "0.2478660096278402\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2020)\n",
    "theta_t = SGD(X = test.iloc[:,0:4], Y = test.iloc[:,5], lamb = 0.001, T=1000)\n",
    "theta_SGD = theta_t[0,0:-1]\n",
    "theta_0_SGD = theta_t[0,-1]\n",
    "print(theta_SGD)\n",
    "print(theta_0_SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar datos para prueba y entrenamiento\n",
    "np.random.seed(2020)\n",
    "train = data.sample(frac = 0.8, random_state = 2020) # Fijamos la semilla con random_state\n",
    "test = data.drop(train.index)\n",
    "\n",
    "# Extraer variables para la clasificación\n",
    "data_vars = train.iloc[:,0:4]\n",
    "vars_train = data_vars.to_numpy()\n",
    "data_labels = train.iloc[:,5]\n",
    "labels_train = data_labels.to_numpy()\n",
    "\n",
    "theta = np.array([0.0, 0.0, 0.0, 0.0])\n",
    "theta_0 = 0.0\n",
    "etha = 0.0001\n",
    "lamb = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n de X:  0\n",
      "n para descenso:  0\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-d2459d3fb731>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlambdas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-2\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m1e-1\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlamb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlambdas\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0merror_SVM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCV_SVM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheta_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0metha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlamb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlamb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_SVM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-fdec8dd3e77e>\u001b[0m in \u001b[0;36mCV_SVM\u001b[0;34m(D, k, theta, theta_0, etha, lamb)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mY_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mY_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtheta_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheta\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mtheta_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheta_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0metha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlamb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlamb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m#Se calcula el error en esa primer corrida\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-f81a7a1e3916>\u001b[0m in \u001b[0;36mSVM\u001b[0;34m(X, Y, theta, theta_0, etha, lamb, eps, MAX)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# Descenso por gradiente\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'n para descenso: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheta\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0metha\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum_theta\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlamb\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mtheta_0\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtheta_0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0metha\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum_theta_0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "error_SVM=[]\n",
    "lambdas = [1e-4, 1e-3, 1e-2,  1e-1,  1]\n",
    "for lamb in lambdas:\n",
    "    error_SVM.append(CV_SVM(D = train, k = 5, theta = theta, theta_0 = theta_0, etha = etha, lamb = lamb))\n",
    "print(error_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n de X:  120\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-4066234bd1fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtheta_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta_0_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvars_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheta_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0metha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlamb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlamb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-36-f81a7a1e3916>\u001b[0m in \u001b[0;36mSVM\u001b[0;34m(X, Y, theta, theta_0, etha, lamb, eps, MAX)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# Evaluacion de la suma para la actualizacion el descenso por gradiente\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0msum_theta\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mclasifica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0msum_theta_0\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mclasifica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-e2b5e2ac0677>\u001b[0m in \u001b[0;36mclasifica\u001b[0;34m(x, y, theta, theta_0)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \"\"\"\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtheta_0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "theta_opt, theta_0_opt, t, error = SVM(X = vars_train, Y = labels_train, theta = theta, theta_0 = theta_0, etha = etha, lamb = lamb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num iteraciones:  5000\n",
      "Error de aprox:  7.052974922466988e-07\n",
      "Jacobiano de aprox:  0.0034621843893957614\n"
     ]
    }
   ],
   "source": [
    "print('Num iteraciones: ', t)\n",
    "print('Error de aprox: ', error)\n",
    "print('Jacobiano de aprox: ', jac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_sgd = SGD(X = vars_train, Y = labels_train, lamb = lamb, eps = 1e-8, T = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.43078276  1.69859461 -3.54360698 -1.83438732  0.38822382]]\n"
     ]
    }
   ],
   "source": [
    "print(theta_sgd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
