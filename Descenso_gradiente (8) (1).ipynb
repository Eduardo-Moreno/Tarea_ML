{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from random import seed\n",
    "from random import randrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectura de datos\n",
    "data = pd.read_csv('iris.data',header=None)\n",
    "data.columns = ['Sepal.length', 'Sepal.width', 'Petal.length', 'Petal.width', 'Species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de clasificación\n",
    "def classificador(x, y, theta, theta_0, tipo):\n",
    "    z = y*(np.dot(x, theta) + theta_0)\n",
    "    \n",
    "    if z < 1.0:\n",
    "        z = -1\n",
    "    else:\n",
    "        z = 0\n",
    "    \n",
    "    return z\n",
    "\n",
    "# Función de pérdida\n",
    "def loess(X, Y, theta, theta_0, etha, lamb):\n",
    "    \n",
    "    suma = 0\n",
    "    n = X.shape[0]\n",
    "        for i in range(n):\n",
    "        loss_h = np.dot(y[i],np.dot(np.transpose(theta),x[i])+theta0)\n",
    "        if loss_h >= 1:\n",
    "            suma += 0\n",
    "        else:\n",
    "            suma += (1-loss_h)\n",
    "            \n",
    "    return sum\n",
    "\n",
    "# Jacobiano\n",
    "def jacob(X, Y, theta, theta_0, lamb):\n",
    "    nr, nc = X.shape\n",
    "    suma_jac = 0\n",
    "    \n",
    "    for i in range(nr):\n",
    "        specie = Y.loc[i][0]\n",
    "        # Positivo: Setosa, Negativo: el resto\n",
    "        if specie == 'Iris-setosa':\n",
    "            y = 1\n",
    "        else:\n",
    "            y = -1\n",
    "        v = y*(np.dot(X.loc[i], theta) + theta_0)\n",
    "        if v < 1.0:\n",
    "            L = 1-v\n",
    "        else:\n",
    "            L = 0\n",
    "        suma_jac = suma_jac + L\n",
    "    \n",
    "    jac = (1/nr)*suma_jac + (lamb/2)*np.dot(theta, theta)\n",
    "    return jac\n",
    "\n",
    "# Método de descenso por gradiente\n",
    "\n",
    "def SVM(X, Y, theta, theta_0, etha, lamb, eps = 1e-8):\n",
    "    \"\"\" Funcion que realiza el aglrotimo de Support Vector Machine - Descenso en Gradiente\n",
    "    Inputs:\n",
    "    x - vector de características a clasificar\n",
    "    y - vector de etiquetas de las características (-1 o 1)    \n",
    "    theta- incializacion de parametro theta\n",
    "    theta0 - inicializacion de parametro theta0\n",
    "    eta - tasa de aprendizaje\n",
    "    lambda_ - factor de regularizacion\n",
    "    \n",
    "    Outputs:\n",
    "    teta = vector para formar el plano\n",
    "    teta_0 = escalar para desplazar el plano \n",
    "    \n",
    "    \"\"\"\n",
    "    sum_theta = 0\n",
    "    sum_theta_0 = 0\n",
    "    n = x.shape[0]\n",
    "    error = 10\n",
    "    \n",
    "    while error >= eps:\n",
    "        theta_aux = theta\n",
    "        theta_0_aux = theta_0\n",
    "        \n",
    "        for i in range(n):\n",
    "            sum_theta += classificador(theta_,theta0_,x[i],y[i])*y[i]*x[i]\n",
    "        for j in range(n):\n",
    "            sum_theta_0 += classificador(theta_,theta0_,x[i],y[i])*y[i]\n",
    "        \n",
    "        theta = theta - etha*((suma1/x.shape[0])+lamb*theta)\n",
    "        theta_0 = theta_0 - etha*((suma2/x.shape[0]))\n",
    "        \n",
    "        error = abs(jacob(X, Y, theta, theta_0, lamb) - jacob(X, Y, theta_aux, theta_0_aux,lamb))\n",
    "    return theta, theta_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['Sepal.length', 'Sepal.width']]\n",
    "Y = data[['Species']]\n",
    "theta = np.array([1.0, 1.0])\n",
    "theta_0 = 1.0\n",
    "etha = 0.1\n",
    "lamb = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_f, theta_0_f = descenso_gradiente(X, Y, theta, theta_0, etha, lamb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.051791675594372616"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacob(X, Y, theta_f, theta_0_f, lamb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
