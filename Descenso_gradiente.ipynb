{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tabulate\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from random import seed\n",
    "from random import randrange\n",
    "import seaborn as sns\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lectura y procesamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lectura de datos\n",
    "data = sns.load_dataset('iris')\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se ajustará la categoría a clasificar, la cual será setosa contra el resto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiar ajuste de datos para clasificar setosa\n",
    "data['categoria'] = [1 if x =='setosa' else -1 for x in data['species']] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Máquinas de soporte vectorial (SVM) utilizando el método de descenso por gradiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función clasifica\n",
    "def clasifica(x, y, theta, theta_0):\n",
    "    \"\"\" DEF: Evalúa la predicción de la categoría en base al modelo (theta, theta_0)\n",
    "    Inputs:\n",
    "    x: vector de caracteristicas\n",
    "    y: vector de etiquetas\n",
    "    theta: vector\n",
    "    theta_0: escalar\n",
    "    Outputs:\n",
    "    value: -1 si la clasific es incorrecta, 0 si lo es\n",
    "    \"\"\"\n",
    "    \n",
    "    # Regla de clasificación\n",
    "    z = y*(np.dot(theta,np.transpose(x)) + theta_0)\n",
    "    if z < 1 :\n",
    "        value = -1\n",
    "    else:\n",
    "        value = 0\n",
    "\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loess(x, y, theta, theta_0):\n",
    "    \"\"\" DEF: Evaluación en la función de perdida\n",
    "    Inputs:\n",
    "    x: vector de características\n",
    "    y: vector de etiquetas\n",
    "    theta: vector normal del hiperplano\n",
    "    theta_0: nivel base del hiperplano (pseudo-ordenada al origen)\n",
    "    Outputs:\n",
    "    suma = valor de pérdida  \n",
    "    \"\"\"\n",
    "    \n",
    "    suma = 0\n",
    "    H = 0\n",
    "    n = x.shape[0]\n",
    "    \n",
    "    for i in range(n):\n",
    "        H = y[i]*(np.dot(theta, x[i]) + theta_0)\n",
    "        if H >= 1:\n",
    "            suma += 0\n",
    "        else:\n",
    "            suma += (1-H)\n",
    "            \n",
    "    return suma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jacob(X, Y, theta, theta_0, lamb):\n",
    "    \"\"\" DEF: Cálculo del jacobiano\n",
    "    Inputs:\n",
    "    X: matriz de características\n",
    "    Y: vector de etiquetas\n",
    "    theta: vector normal del hiperplano\n",
    "    theta_0: nivel base del hiperplano (pseudo-ordenada al origen)\n",
    "    lamb: escalar que indica la tasa de aprendizaje\n",
    "    Outputs:\n",
    "    value = valor del jacobiano\n",
    "    \"\"\"\n",
    "    \n",
    "    n = X.shape[0]\n",
    "    jacobiano = loess(X, Y, theta, theta_0)/n + (lamb/2.0)*np.linalg.norm(theta)\n",
    "\n",
    "    return jacobiano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para descenso por gradiente\n",
    "def SVM(X, Y, theta, theta_0, etha, lamb, eps = 1e-8, MAX = 3000):\n",
    "    \"\"\" DEF: Máquina de soporte vectorial en base al método descenso en gradiente\n",
    "    Inputs:\n",
    "    X: matriz de características\n",
    "    Y: vector de etiquetas\n",
    "    theta: vector normal del hiperplano\n",
    "    theta_0: nivel base del hiperplano (pseudo-ordenada al origen)\n",
    "    lamb: escalar que indica la tasa de aprendizaje\n",
    "    Outputs:\n",
    "    theta = hiperplano final\n",
    "    theta_0 = base del hiperplano final (pseudo-ordenada al origen)\n",
    "    \"\"\"\n",
    "    \n",
    "    n = X.shape[0]\n",
    "    sum_theta = 0\n",
    "    sum_theta_0 = 0\n",
    "    error = 10\n",
    "    t = 0\n",
    "    \n",
    "    # Salir del ciclo si alcanzamos la tolerencia deseada o bien porque se llegó al máximo de iteraciones permitidas\n",
    "    while error >= eps and t < MAX:\n",
    "        # Guardar parametros en tiempo: t-1\n",
    "        theta_old = theta\n",
    "        theta_0_old = theta_0\n",
    "        \n",
    "        # Evaluacion de la suma para la actualizacion el descenso por gradiente\n",
    "        for i in range(n):\n",
    "            sum_theta += clasifica(X[i], Y[i], theta, theta_0)*Y[i]*X[i]\n",
    "            sum_theta_0 += clasifica(X[i], Y[i], theta, theta_0)*Y[i]\n",
    "        \n",
    "        # Descenso por gradiente\n",
    "        theta = theta - etha*((sum_theta/n) + lamb*theta)\n",
    "        theta_0= theta_0 - etha*((sum_theta_0/n))\n",
    "        \n",
    "        # Calculo del error\n",
    "        error = abs(jacob(X, Y, theta, theta_0, lamb) - jacob(X, Y, theta_old, theta_0_old, lamb))\n",
    "        t += 1\n",
    "    \n",
    "    jac = jacob(X, Y, theta, theta_0, lamb)\n",
    "    return theta, theta_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CV_SVM(D, k, theta, theta_0, etha, lamb):\n",
    "    \"\"\" DEF: Computa la validación cruzada para determinar la lambda que minimiza el error\n",
    "    Inputs:\n",
    "    D:matriz de características\n",
    "    k:número de subconjutos a probar\n",
    "    theta: vector normal del hiperplano\n",
    "    theta_0: nivel base del hiperplano (pseudo-ordenada al origen)\n",
    "    etha: escalar\n",
    "    lamb: escalar que indica la tasa de aprendizaje\n",
    "\n",
    "    Outputs:\n",
    "    error_promedio: error promedio de cada clasificación\n",
    "    \"\"\"\n",
    "    \n",
    "    errors = []\n",
    "    n = D.shape[0]\n",
    "    \n",
    "    # Calculo del tamaño de los bloques\n",
    "    n = int((n / k))\n",
    "    \n",
    "    for i in range (0,k):\n",
    "        init = n*i\n",
    "        fin = n*(i+1)\n",
    "        # Selecionar datos del i-esimo bloque para prueba y entrenamiento\n",
    "        test_i = D.iloc[init:fin,:]\n",
    "        train_i = D.drop(test_i.index)\n",
    "        X_train = train_i.iloc[:,0:4]\n",
    "        X_train = X_train.to_numpy()\n",
    "        Y_train = train_i.iloc[:,5]\n",
    "        Y_train = Y_train.to_numpy()\n",
    "        # Obtener el i-esimo hiperplano utilizando metodología de descenso por gradiente\n",
    "        theta,theta_0 = SVM(X = X_train, Y = Y_train, theta = theta , theta_0 = theta_0, etha = etha, lamb = lamb)\n",
    "        X_test = test_i.iloc[:,0:4]\n",
    "        X_test = X_test.to_numpy()\n",
    "        Y_test = test_i.iloc[:,5]\n",
    "        Y_test = Y_test.to_numpy()\n",
    "        # Calculo del i-esimo error\n",
    "        error_i = error(X = X_test, Y = Y_test, theta = theta, theta_0 = theta_0)\n",
    "        errors.append(error_i)\n",
    "    \n",
    "    error_promedio = np.mean(errors)\n",
    "\n",
    "    return error_promedio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(X, Y, theta, theta_0):\n",
    "    \"\"\" DEF: Cómputo del error en base al modelo definido por el hiperplano theta y theta_0\n",
    "    Inputs:\n",
    "    X: vector de caracteristicas\n",
    "    Y: vector de clases\n",
    "    theta: vector normal del hiperplano\n",
    "    theta_0: nivel base del hiperplano (pseudo-ordenada al origen)    \n",
    "    Outputs:\n",
    "    error_prom: error promedio de datos mal clasificadas\n",
    "    \"\"\"\n",
    "    \n",
    "    n = len(X)\n",
    "    suma = 0\n",
    "    error_prom = 0\n",
    "    X = np.squeeze(np.asarray(X))\n",
    "    Y = np.squeeze(np.asarray(Y))\n",
    "    \n",
    "    for i in np.arange(n):\n",
    "        clasificador = Y[i]*((np.dot(theta,X[i])) + theta_0)\n",
    "        # Regla de clasificación correcta\n",
    "        if clasificador <= 0:\n",
    "            suma += 1         \n",
    "    error_prom += suma\n",
    "    \n",
    "    error_prom = error_prom/n\n",
    "    return error_prom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descenso por gradiente estocástico (SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD(X, Y, lamb, T = 3000):\n",
    "    \"\"\" DEF: Cómputo de vector normal del hiperplano separador en base a metodología descenso por gradiente estocástico\n",
    "    Inputs:\n",
    "    X: matriz de caracteristicas\n",
    "    Y: matriz de etiquetas\n",
    "    T: máximo de iteraciones\n",
    "    lamb: Párametro lambda \n",
    "    Outputs:\n",
    "    theta_t: parámetros del hiperparámetro obtenido por el método\n",
    "    \"\"\"\n",
    "    \n",
    "    n = X.shape[0]\n",
    "    X = np.matrix(X)\n",
    "    ones = np.matrix(np.ones((X.shape[0],1)))\n",
    "    X = np.append(X, ones, axis=1)\n",
    "    Y = np.matrix(Y).reshape(Y.shape[0],1)\n",
    "    theta_t = np.matrix(np.zeros(X.shape[1]))\n",
    "    \n",
    "    for t in range(T):\n",
    "        # Seleccionar observación de manera aleatoria\n",
    "        i = np.random.randint(n)\n",
    "        etha = 1/(t+1)\n",
    "        theta_t = np.squeeze(np.asarray(theta_t))\n",
    "        x_i = np.squeeze(np.asarray(X[i]))\n",
    "        # Regla de ajuste por método de descenso por gradiente estocástico\n",
    "        if np.dot(theta_t,x_i)*Y[i] < 1:\n",
    "            l_h =  -1\n",
    "        else:\n",
    "            l_h =  0\n",
    "        # Ajuste del hiperparámetro\n",
    "        theta_t = theta_t - etha*(l_h*Y[i]*x_i + (lamb)*theta_t)\n",
    "        \n",
    "    return np.array(theta_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CV_SGD(D, k, lamb):\n",
    "    \"\"\" DEF: Computa la validación cruzada para determinar la lambda que minimiza el error\n",
    "    Inputs:\n",
    "    D: matriz de características\n",
    "    k: número de subconjutos a probar\n",
    "    Outputs:\n",
    "    error_promedio: error promedio de cada clasificación\n",
    "    \"\"\"\n",
    "    \n",
    "    errors = []\n",
    "    n = D.shape[0]\n",
    "    # Calculo del tamaño de los bloques\n",
    "    n = int((n / k))\n",
    "    \n",
    "    for i in range (0,k):\n",
    "        init = n*i\n",
    "        fin = n*(1+i)\n",
    "        # Selecionar datos del i-esimo bloque para prueba y entrenamiento\n",
    "        test_i = D.iloc[init:fin,:]\n",
    "        train_i = D.drop(test_i.index)\n",
    "        # Obtener el i-esimo hiperplano utilizando metodología de descenso por gradiente estocástico\n",
    "        X = train_i.iloc[:,0:4]\n",
    "        Y = train_i.iloc[:,5]\n",
    "        theta_t = SGD(X = X, Y = Y, lamb = lamb)\n",
    "        theta = theta_t[0,0:-1]\n",
    "        theta_0 = theta_t[0,-1]\n",
    "        # Calculo del i-esimo error\n",
    "        X = test_i.iloc[:,0:4]\n",
    "        Y = test_i.iloc[:,5]\n",
    "        e_i = error(X = X, Y = Y, theta = theta, theta_0 = theta_0)\n",
    "        errors.append(e_i)\n",
    "    \n",
    "    error_promedio = np.mean(errors)\n",
    "\n",
    "    return error_promedio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba del algoritmo: descenso por gradiente estocástico (SGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separación de datos para prueba y entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar datos para prueba y entrenamiento\n",
    "np.random.seed(2020)\n",
    "train = data.sample(frac = 0.8, random_state = 2020) # Fijamos la semilla con random_state\n",
    "test = data.drop(train.index)\n",
    "\n",
    "# Extraer variables para la clasificación\n",
    "data_vars = train.iloc[:,0:4]\n",
    "vars_train = data_vars.to_numpy()\n",
    "data_labels = train.iloc[:,5]\n",
    "labels_train = data_labels.to_numpy()\n",
    "\n",
    "test_vars = test.iloc[:,0:4]\n",
    "vars_test = test_vars.to_numpy()\n",
    "test_labels = test.iloc[:,5]\n",
    "labels_test = test_labels.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cómputo de $\\lambda$ óptima en base al data de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "error_sgd = []\n",
    "lambdas = [1e-4, 1e-3, 1e-2,  1e-1,  1]\n",
    "for lamb in lambdas:\n",
    "    error_sgd.append(CV_SGD(D = train, k = 5, lamb = lamb))\n",
    "print(error_sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para cualquier $\\lambda \\in \\{ 10^{-4}, 10^{-3}, 10^{-2}, 10^{-1}, 1\\}$ el error es $0$, por convención se utilizará $\\lambda = 10^{-3}.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se muestran los resultados de función predefinida `SGD`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parámetros del hiperplano SGD:  [ 0.74724692  1.71755737 -2.87446804 -1.1700243 ]\n",
      "Pseudo-ordenada al origen SGD:  0.23579375290931415\n",
      "Error de método SGD:  0.0\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2020)\n",
    "theta_t = SGD(X = train.iloc[:,0:4], Y = train.iloc[:,5], lamb = 0.001, T=1000)\n",
    "theta_SGD = theta_t[0,0:-1]\n",
    "theta_0_SGD = theta_t[0,-1]\n",
    "print('Parámetros del hiperplano SGD: ', theta_SGD)\n",
    "print('Pseudo-ordenada al origen SGD: ', theta_0_SGD)\n",
    "error_SGD = error(vars_test, labels_test, theta_SGD, theta_0_SGD)\n",
    "print('Error de método SGD: ', error_SGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba del algoritmo: descenso por gradiente (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar datos para prueba y entrenamiento\n",
    "np.random.seed(2020)\n",
    "train = data.sample(frac = 0.8, random_state = 2020) # Fijamos la semilla con random_state\n",
    "test = data.drop(train.index)\n",
    "\n",
    "# Extraer variables para la clasificación\n",
    "data_vars = train.iloc[:,0:4]\n",
    "vars_train = data_vars.to_numpy()\n",
    "data_labels = train.iloc[:,5]\n",
    "labels_train = data_labels.to_numpy()\n",
    "\n",
    "test_vars = test.iloc[:,0:4]\n",
    "vars_test = test_vars.to_numpy()\n",
    "test_labels = test.iloc[:,5]\n",
    "labels_test = test_labels.to_numpy()\n",
    "\n",
    "# Parámetros de inicio\n",
    "theta = np.array([0.0, 0.0, 0.0, 0.0])\n",
    "theta_0 = 0.0\n",
    "etha = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.008333333333333333]\n"
     ]
    }
   ],
   "source": [
    "error_SVM=[]\n",
    "lambdas = [1e-4, 1e-3, 1e-2,  1e-1,  1]\n",
    "for lamb in lambdas:\n",
    "    error_SVM.append(CV_SVM(D = train, k = 5, theta = theta, theta_0 = theta_0, etha = etha, lamb = lamb))\n",
    "print(error_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lambdas, error_SVM, color = 'red')\n",
    "plt.title('Error de método SVM')\n",
    "plt.xlabel('lambda')\n",
    "plt.ylabel('error')\n",
    "#plt.grid()\n",
    "plt.grid(linestyle='--', linewidth=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se muestran los resultados de función predefinida `SVM`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parámetros del hiperplano SVM:  [  8.34218174  20.85576294 -31.01597078 -14.73339556]\n",
      "Pseudo-ordenada al origen SVM:  [4.19432833]\n",
      "Error de método SVM:  0.0\n",
      "Jacobiano evaluado en parámetros óptimos SVM:  0.02051595861769767\n"
     ]
    }
   ],
   "source": [
    "theta_SVM, theta_0_SVM = SVM(X = vars_train, Y = labels_train, \n",
    "                             theta = np.array([0.0, 0.0, 0.0, 0.0]), theta_0 = np.array([0.0]),\n",
    "                             etha = 1e-4, lamb = 1e-4)\n",
    "print('Parámetros del hiperplano SVM: ', theta_SVM)\n",
    "print('Pseudo-ordenada al origen SVM: ', theta_0_SVM)\n",
    "error_SVM = error(vars_test, labels_test, theta_SVM, theta_0_SVM)\n",
    "print('Error de método SVM: ', error_SVM)\n",
    "print('Jacobiano evaluado en parámetros óptimos SVM: ', jacob(X = vars_train, Y = labels_train, \n",
    "                                                          theta = theta_SVM, theta_0 = theta_0_SVM, lamb = 1e-3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba del algoritmo: perceptrón"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- BRAULIO: AQUI VA TU CÓDIGO, PUEDES CHECAR EL FORMATO QUE LE DI A LAS GRÁFICAS Y FUNCIONES PARA QUE LAS TOMES COMO BASE Y TENER EL MISMO TIPO\n",
    "\n",
    "\n",
    "-- POR ÚLTIMO: NO OLVIDES AGREGAR LOS RESULTADOS DEL PERCEPTRON (THETHA_0, THETA Y ERROR A LA SIGUIENE TABLA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tabulate([['SGD', theta_SVM, theta_0_SVM, error_SVM], ['SVM', theta_SGD, theta_0_SGD, error_SGD]], \n",
    "               headers=['Método', 'theta', 'theta_0', 'Error']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
